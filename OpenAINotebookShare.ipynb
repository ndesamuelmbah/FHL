{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5dd4efd",
   "metadata": {},
   "source": [
    "## You will need the following 3 Packages\n",
    "\n",
    "#### re, requests, json, openai, os, pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66183554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment and run the next line if you need to install or upgrade openai\n",
    "# !pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b3fcad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, requests, json, openai, os, pandas as pd\n",
    "env = os.environ\n",
    "OPENAI_PUBLIC_KEY = env['OPENAI_PUBLIC_KEY']\n",
    "OPENAI_MSFT_KEY = env['OPENAI_MSFT_KEY']\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://dalle-exploration.openai.azure.com/\"\n",
    "openai.api_version = \"2022-12-01\"\n",
    "openai.api_key = OPENAI_MSFT_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f962d00",
   "metadata": {},
   "source": [
    "# Add Environment variables.\n",
    "\n",
    "### Here is how to set your environment variables. Start->edit system environment variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c5d59c",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"AddEnvVariables.png\" width=300 height=200 />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c7f6a28",
   "metadata": {},
   "source": [
    "### Get your OPENAI API KEY from azure open ai console.\n",
    "\n",
    "link = https://ms.portal.azure.com/#@microsoft.onmicrosoft.com/resource/subscriptions/67aa06b0-2686-40dc-92b0-1316ea0304d9/resourceGroups/Shared_AI_Experience/providers/Microsoft.CognitiveServices/accounts/DALLE-Exploration/cskeys\n",
    "<img align=\"left\" src=\"GetApiKeys.png\" width=300 height=200 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10148dc",
   "metadata": {},
   "source": [
    "### Access Model via method 1 - Using openai library.\n",
    "#### I have decided to always pass the name of the actual model and then have a look up that tells me the deployment name.\n",
    "#### The deployment names as of 02/07 1 PM are in the image below but you can always access the lattest from this link\n",
    "https://oai.azure.com/portal/e9d583b4c7a0488cb3e7acfbb439f609/deployment#\n",
    "\n",
    "<img align=\"left\" src=\"DeployedModels.png\" width=300 height=200 />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef466a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"\\n\\nThe US can fit in an African Map approximately 3.5 times.\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1675805401,\n",
      "  \"id\": \"cmpl-6hPpJKccQz4eyWqZk1SiLjAMtOwBi\",\n",
      "  \"model\": \"text-davinci-002\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 16,\n",
      "    \"prompt_tokens\": 12,\n",
      "    \"total_tokens\": 28\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#Define the way you want to get response from the model.\n",
    "\n",
    "def get_promp_response_from_model(model, prompt, max_tokens = 4000, temperature = 1, top_p=0.5):\n",
    "    \n",
    "    lookup = {'text-davinci-002': 'text-davinci-002',\n",
    "             'text-chat-davinci-002': 'chatGPTtest',\n",
    "             'code-davinci-002': 'code-davinci-002',\n",
    "             'text-davinci-003': 'test003',\n",
    "             'text-ada-001': 'text-ada-001'}\n",
    "    try:\n",
    "        response  = openai.Completion.create(\n",
    "          engine=lookup[model],\n",
    "          prompt=prompt,\n",
    "          temperature=temperature,\n",
    "          max_tokens=max_tokens,\n",
    "          top_p=top_p,\n",
    "          frequency_penalty=0,\n",
    "          presence_penalty=0,\n",
    "          best_of=1,\n",
    "          stop=None)\n",
    "        return [model, prompt, response]\n",
    "    except Exception as error:\n",
    "        print(f'Exception ({error}) occurred')\n",
    "        return  [model, prompt, error]\n",
    "    \n",
    "#Here is an example.\n",
    "prompt = \"How many times can the US fit in an African Map?\"\n",
    "response = get_promp_response_from_model('text-davinci-002', prompt)\n",
    "print(response[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96902a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d68beae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The US can fit in an African Map approximately 3.5 times.\n"
     ]
    }
   ],
   "source": [
    "#You can access the response text by\n",
    "responseText = response[2].choices[0].text \n",
    "print(responseText) #try ' '.join(responseText.strip().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79c01525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example using rest\n",
    "OPENAI_PUBLIC_KEY = env['OPENAI_PUBLIC_KEY']\n",
    "OPENAI_MSFT_KEY = env['OPENAI_MSFT_KEY']\n",
    "\n",
    "base_url = \"https://dalle-exploration.openai.azure.com\"\n",
    "deployment_name =\"text-davinci-002\"\n",
    "\n",
    "def get_full_model_url(model):\n",
    "    lookup = {'text-davinci-002': 'text-davinci-002',\n",
    "             'text-chat-davinci-002': 'chatGPTtest',\n",
    "             'code-davinci-002': 'code-davinci-002',\n",
    "             'text-davinci-003': 'test003',\n",
    "             'text-ada-001': 'text-ada-001'}\n",
    "    assert model in lookup, f\"Sorry, could not find a deployed model called '{model}'\"\n",
    "    deplyment_name = lookup[model]\n",
    "    return f\"{base_url}/openai/deployments/{deplyment_name}/completions?api-version=2022-12-01\"\n",
    "\n",
    "def form_headers_and_parameters(prompt,\n",
    "          temperature=1,\n",
    "          max_tokens=400,\n",
    "          top_p=0.7,\n",
    "          frequency_penalty=0,\n",
    "          presence_penalty=0,\n",
    "          best_of=1):\n",
    "    data = {        \n",
    "            \"prompt\":prompt, #Only required param\n",
    "            'temperature':1,\n",
    "            'max_tokens':400,\n",
    "            'top_p':0.7,\n",
    "            'frequency_penalty':0,\n",
    "            'presence_penalty':0,\n",
    "            'best_of':1    \n",
    "    }\n",
    "\n",
    "    headers={\n",
    "            \"api-key\": OPENAI_MSFT_KEY,\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "    return data, headers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "700cf24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'cmpl-6hQ7c5JIs3gEtnoiDDDE20SZJvWNt',\n",
       " 'object': 'text_completion',\n",
       " 'created': 1675806536,\n",
       " 'model': 'text-davinci-002',\n",
       " 'choices': [{'text': '\\n\\nThe greatest invention ever is the wheel.',\n",
       "   'index': 0,\n",
       "   'finish_reason': 'stop',\n",
       "   'logprobs': None}],\n",
       " 'usage': {'completion_tokens': 10, 'prompt_tokens': 7, 'total_tokens': 17}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, headers = form_headers_and_parameters(prompt=\"What is the greatest invention ever?\")\n",
    "\n",
    "r = requests.post(get_full_model_url('text-davinci-002'), \n",
    "      headers=headers,\n",
    "      json = data\n",
    "    )\n",
    "\n",
    "response = r.json()# or json.loads(r.text)\n",
    "formatted_response = json.dumps(response, indent=4)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df447b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will be adding more apis as time goes on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
